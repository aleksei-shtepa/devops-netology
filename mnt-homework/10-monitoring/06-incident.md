# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


|Постмортем| |
|---------------------------:|---|
|*Краткое описание инцидента*|Сбой системы оркестрации кластерами MySQL при рассогласованности данных между дата-центрами|
|*Предшествующие события*    |Замена неисправных компонентов сетевого хранилища привела с временному (43 секунды) разрыву сети и потери связи между дата-центрами.|
|*Причина инцидента*         |Система оркестрации кластера MySQL в условиях отсутствия связи между дата-центрами не смогла выбрать лидера, так как топология кластера находилась в "неожиданном" состоянии.[^1][^2]|
|*Воздействие*               |Поломка системы оркестрации кластеров MySQL привела к накоплению несогласованных данных между дата-центрами. Восстановление согласованности данных произошло по истечению 24 часов и 11 минут. В течении этого времени пользователи могли получать устаревшие данные.|
|*Обнаружение*               |Дежурный системный инженер через систему оповещения о сбоях.|
|*Реакция*                   |Оркестрация кластеров базы данных переведена в ручной режим, подключены инженеры из команды разработчиков баз данных. Из за низкой скорости восстановления из резервной копии во время пиковых нагрузок на сервис время восстановление было гораздо больше прогнозируемого и составило 24 часа.|
|*Восстановление*            |Для сохранения накопленных несогласованных данных принято решение пожертвовать доступностью webhook и латентностью операций записи. Для этих целей восстановили данные из резервной копии, накатили на них бинарные логи репликации и вручную переконфигурировали топологию кластеров MySQL.[^3]|
|*Таймлайн*                  |**2018-10-21 22:52z** Нарушение целостности кластера MySQL в следствии потери связи между дата-центрами.</br>**2018-10-21 22:52z** Оркестратор начал процесс перестройки кластера и выбора нового лидера. В результате два дата-центра начали накапливать новые пользовательские данные. После восстановления связи между дата-центрами оказалось, что в каждом из них есть данные отсутствующие на другом и оркестратор не смог выбрать лидера.</br>**2018-10-21 22:54z** Дежурные системные инженеры стали получать уведомления о сбоях</br>**2018-10-21 23:07z** Команда реагирования переключила управление кластером в ручной режим</br>**2018-10-21 23:19z** Для уменьшения нагрузки отключены push-уведомления, webhooks и сборки GitHub Pages.</br>**2018-10-22 00:05z** Команда реагирования начала процесс восстановления из резервной копии БД, синхронизацию её со всеми узлами, накатывания данных из backlog (входящего трафика) и восстановление топологии кластера.</br>**2018-10-22 11:12z** Закончена синхронизация резервированных данных в кластере и происходило накатывание новых изменений и backlog.</br>**2018-10-22 16:24z** Закончена синхронизация данных и включена оригинальная топология кластера. Восстановлена стабильная работа основного функционала.</br>**2018-10-22 16:45z** Включены push-уведомления, webhooks и сборки GitHub Pages. В backlog собралось около 200 000 webhooks с истекшим временем жизни. Для них был скорректирован TTL.</br>**2018-10-22 23:03z** Все ожидающие сборки webhooks и GitHub Pages были обработаны, и была подтверждена целостность и правильная работа всех систем.|
|*Последующие действия*      |Проработка механизма резервирования N+1 на уровне дата-центров и введение практик хаос-инжиниринга.|

[^1]: Нормальная топология кластера:
    ![normal-topology](https://github.blog/wp-content/uploads/2018/10/normal-topology.png?resize=800%2C600 "Нормальная топология кластера")

[^2]: Сломанная топология кластера:
    ![invalid-topology](https://github.blog/wp-content/uploads/2018/10/invalid-topology.png?resize=800%2C600 "Сломанная топология кластера")

[^3]: План восстановления кластера:
    ![recovery-flow](https://github.blog/wp-content/uploads/2018/10/recovery-flow.png?resize=800%2C600 "План восстановления кластера")